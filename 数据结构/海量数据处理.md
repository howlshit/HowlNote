> 虽然做了笔记，但还老是忘，因为不常使用吗？





## 1. 海量数据处理

常见的问题如下：



10亿篇文章，如何找出其中出现次数最多的100个词（Trim树）

10亿个数字，取最小的100个数（Top K）

在2.5亿个整数中找出不重复的整数（重复问题）

两个大文件，找出交集？（利用Top K问题，使用相同的hash函数分片，那么相同的数据会被分到相同的片段）









## 2 Top K 问题

10亿个数字，找出现次数最多的一个或多个



（分治 + hashmap + 排序）

- 把数字Hash(num)%1000值，存储到1000个小文件中
- 每个小文件，构建HashMap（num，times），同时记录当前出现次数最多的num（多个时，就记录多个）
- 得到1000个小文件中的出现次数最多的num，再依据常规的排序算法得到总体上出现次数最多的num



（堆排序，先排前n个，然后遍历所有数字）

- 堆排序（nlogN）



（partition算法，经常二者比较，缺点为：内存没那么大，适合小数据）

- O(n)，S(1)，但是需要改变输入的数组（就是快排思想）









## 2 不重复/去重问题

10亿个数字中找不重复的



（分治+hashmap+排除重复的）

- 把数字Hash(num)%1000值，存储到1000个小文件中
- 每个小文件后见HashMap（num，times），构建完就遍历去除次数超过1的
- 得到1000个小文件不重复的数字



（bitmap自动去重）

- 构建bitmap，用两个位表示一个数字。出现一次就设置为01，10表示多次，那么最后取出01的标示即可









## 3 中位数

10亿个数快速寻找中位数



- 内存足够：排序。。。
- 内存不够：分桶法（将数字看成二进制，看二进制第一位数字，将数字分成正负两个文件保存，假设file1存整数有6亿个，file0存负数有4亿个，那么中位数在file1上，依次类推）
